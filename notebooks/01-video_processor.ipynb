{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Guia do Projeto - Tech Challenge Fase 4 - Parte 01\n",
                "\n",
                "## Processamento de Vídeo: Fundamentos Teóricos e Práticos\n",
                "\n",
                "Bem-vindo à primeira etapa do nosso pipeline de análise de vídeo. Antes de aplicarmos Inteligência Artificial para detectar faces ou emoções, precisamos dominar a matéria-prima do nosso trabalho: o **vídeo digital**.\n",
                "\n",
                "### O que é um Vídeo Digital?\n",
                "\n",
                "Teoricamente, um vídeo nada mais é do que uma sequência de imagens estáticas (chamadas de **frames** ou quadros) exibidas em alta velocidade para criar a ilusão de movimento. \n",
                "\n",
                "Para processar um vídeo computacionalmente, precisamos entender três conceitos fundamentais:\n",
                "\n",
                "1.  **Frame Rate (FPS - Frames Per Second):** A frequência com que as imagens são exibidas. Vídeos comuns têm 24, 30 ou 60 FPS. Quanto maior o FPS, mais fluido é o movimento, mas maior é o custo computacional para processar.\n",
                "2.  **Resolução:** As dimensões de cada frame (largura x altura em pixels, ex: 1920x1080). Imagens maiores contêm mais detalhes, mas exigem mais memória.\n",
                "3.  **Codecs e Containers:** O arquivo `.mp4` é um container que guarda o vídeo comprimido por um codec (como H.264). Para ler o vídeo, precisamos \"decodificar\" esse arquivo frame a frame.\n",
                "\n",
                "### Objetivos deste Notebook\n",
                "\n",
                "Neste notebook, vamos construir a base de todo o projeto:\n",
                "1.  Entender como a biblioteca **OpenCV** manipula vídeos.\n",
                "2.  Implementar o padrão de projeto **Generator** para processar vídeos longos sem estourar a memória RAM.\n",
                "3.  Criar a classe `VideoProcessor`, que será reutilizada em todas as etapas futuras.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Configuração do Ambiente\n",
                "\n",
                "Utilizaremos o **OpenCV** (`cv2`), a biblioteca padrão da indústria para Visão Computacional. Ela é escrita em C/C++ e possui wrappers para Python, garantindo altíssima performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import os\n",
                "import sys\n",
                "from typing import Generator, Tuple\n",
                "import logging\n",
                "\n",
                "# Configuração de logging para monitorar a execução\n",
                "logging.basicConfig(level=logging.INFO)\n",
                "logger = logging.getLogger(__name__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. A Classe VideoProcessor\n",
                "\n",
                "Para manter nosso código organizado e profissional, não usaremos scripts soltos. Encapsularemos a lógica de leitura de vídeo em uma classe.\n",
                "\n",
                "#### O Padrão Generator (Gerador)\n",
                "\n",
                "Um conceito crucial aqui é o uso de **Generators** do Python (a palavra-chave `yield`). \n",
                "\n",
                "**Por que usar?**\n",
                "Imagine um vídeo de 1 hora em Full HD. Se tentássemos carregar todos os frames em uma lista na memória RAM, o computador travaria (são gigabytes de dados). \n",
                "\n",
                "O `Generator` permite carregar **um frame de cada vez**, processá-lo e descartá-lo antes de carregar o próximo. Isso torna nosso pipeline extremamente eficiente e capaz de processar vídeos de qualquer tamanho."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "class VideoProcessor:\n",
                "    \"\"\"\n",
                "    Classe responsável pelo processamento sequencial de vídeos.\n",
                "    \n",
                "    Atua como uma fachada para a complexidade do OpenCV, gerenciando\n",
                "    a abertura, leitura frame a frame e liberação de recursos.\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, video_path: str):\n",
                "        \"\"\"\n",
                "        Inicializa o processador.\n",
                "        \n",
                "        Args:\n",
                "            video_path (str): Caminho absoluto ou relativo para o arquivo de vídeo.\n",
                "        \"\"\"\n",
                "        # Validação básica de existência do arquivo\n",
                "        if not os.path.exists(video_path):\n",
                "            raise FileNotFoundError(f\"Arquivo de vídeo não encontrado: {video_path}\")\n",
                "        \n",
                "        self.video_path = video_path\n",
                "        \n",
                "        # cv2.VideoCapture é a classe do OpenCV que decodifica o vídeo\n",
                "        self.cap = cv2.VideoCapture(video_path)\n",
                "\n",
                "        if not self.cap.isOpened():\n",
                "            raise ValueError(f\"Não foi possível abrir o vídeo: {video_path}\")\n",
                "        \n",
                "        # Extração de metadados técnicos do vídeo\n",
                "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
                "        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
                "        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
                "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
                "\n",
                "        logger.info(\n",
                "            f\"Vídeo carregado com sucesso: {self.width}x{self.height} @ \"\n",
                "            f\"{self.fps:.2f}fps, {self.frame_count} frames totais.\"\n",
                "        )\n",
                "\n",
                "    def get_frames(self) -> Generator[Tuple[int, float, cv2.Mat], None, None]:\n",
                "        \"\"\"\n",
                "        Gera frames do vídeo sob demanda (Lazy Loading).\n",
                "        \n",
                "        Este método transforma a classe em um iterável eficiente.\n",
                "        \n",
                "        Yields:\n",
                "            Tuple[int, float, cv2.Mat]: Uma tupla contendo:\n",
                "                - frame_num (int): O índice sequencial do frame (0, 1, 2...)\n",
                "                - timestamp (float): O tempo exato do frame em segundos.\n",
                "                - frame (cv2.Mat): A imagem do frame em formato matriz NumPy (BGR).\n",
                "        \"\"\"\n",
                "        frame_num = 0\n",
                "        \n",
                "        while True:\n",
                "            # self.cap.read() decodifica o próximo frame do arquivo\n",
                "            ret, frame = self.cap.read()\n",
                "            \n",
                "            # 'ret' é False quando o vídeo acaba ou ocorre erro\n",
                "            if not ret:\n",
                "                break\n",
                "\n",
                "            # Calculamos o timestamp baseados no FPS\n",
                "            timestamp = frame_num / self.fps if self.fps > 0 else 0\n",
                "            \n",
                "            # A palavra-chave 'yield' pausa a função e entrega o valor,\n",
                "            # retomando daqui na próxima iteração do loop.\n",
                "            yield frame_num, timestamp, frame\n",
                "            \n",
                "            frame_num += 1\n",
                "\n",
                "    def release(self):\n",
                "        \"\"\"\n",
                "        Libera o arquivo de vídeo do sistema operacional.\n",
                "        É uma boa prática fechar recursos externos quando não usados mais.\n",
                "        \"\"\"\n",
                "        self.cap.release()\n",
                "\n",
                "    def get_video_info(self) -> dict:\n",
                "        \"\"\"\n",
                "        Retorna um dicionário com o resumo técnico do vídeo.\n",
                "        Útil para relatórios e logs.\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"fps\": self.fps,\n",
                "            \"frame_count\": self.frame_count,\n",
                "            \"width\": self.width,\n",
                "            \"height\": self.height,\n",
                "            \"duration_seconds\": (\n",
                "                self.frame_count / self.fps if self.fps > 0 else 0\n",
                "            )\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Teste Prático\n",
                "\n",
                "Vamos instanciar nossa classe e verificar se ela consegue ler corretamente os metadados do vídeo de exemplo `meu_video.mp4`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:__main__:Vídeo carregado com sucesso: 1280x720 @ 30.00fps, 3326 frames totais.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Relatório Técnico do Vídeo ===\n",
                        "Resolução: 1280x720 pixels\n",
                        "Taxa de Quadros (FPS): 30.00\n",
                        "Total de Frames: 3326\n",
                        "Duração Total: 110.87 segundos\n"
                    ]
                }
            ],
            "source": [
                "video_path = \"meu_video.mp4\"\n",
                "\n",
                "try:\n",
                "    # 1. Instanciação\n",
                "    processor = VideoProcessor(video_path)\n",
                "    \n",
                "    # 2. Obtenção de Metadados\n",
                "    info = processor.get_video_info()\n",
                "    \n",
                "    print(\"=== Relatório Técnico do Vídeo ===\")\n",
                "    print(f\"Resolução: {info['width']}x{info['height']} pixels\")\n",
                "    print(f\"Taxa de Quadros (FPS): {info['fps']:.2f}\")\n",
                "    print(f\"Total de Frames: {info['frame_count']}\")\n",
                "    print(f\"Duração Total: {info['duration_seconds']:.2f} segundos\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"Ocorreu um erro crítico: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Visualizando a Estrutura dos Dados\n",
                "\n",
                "Para entender o que o computador \"vê\", vamos imprimir as propriedades dos primeiros frames. Note como o `shape` (formato da matriz) corresponde à resolução do vídeo (Altura, Largura, Canais de Cor)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Iniciando leitura sequencial (Stream)...\n",
                        "\n",
                        "[Frame 0000]\n",
                        "  Tempo: 0.000s\n",
                        "  Dados (Matriz): (720, 1280, 3) - (Altura, Largura, Canais BGR)\n",
                        "  Tipo de Dado: uint8 (Inteiros de 8 bits sem sinal)\n",
                        "\n",
                        "[Frame 0001]\n",
                        "  Tempo: 0.033s\n",
                        "  Dados (Matriz): (720, 1280, 3) - (Altura, Largura, Canais BGR)\n",
                        "  Tipo de Dado: uint8 (Inteiros de 8 bits sem sinal)\n",
                        "\n",
                        "[Frame 0002]\n",
                        "  Tempo: 0.067s\n",
                        "  Dados (Matriz): (720, 1280, 3) - (Altura, Largura, Canais BGR)\n",
                        "  Tipo de Dado: uint8 (Inteiros de 8 bits sem sinal)\n",
                        "\n",
                        "Recursos liberados.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Iniciando leitura sequencial (Stream)...\")\n",
                "\n",
                "# O loop consome o Generator frame a frame\n",
                "for frame_num, timestamp, frame in processor.get_frames():\n",
                "    # Vamos inspecionar apenas os primeiros 3 frames\n",
                "    if frame_num >= 3:\n",
                "        break\n",
                "        \n",
                "    print(f\"\\n[Frame {frame_num:04d}]\")\n",
                "    print(f\"  Tempo: {timestamp:.3f}s\")\n",
                "    print(f\"  Dados (Matriz): {frame.shape} - (Altura, Largura, Canais BGR)\")\n",
                "    print(f\"  Tipo de Dado: {frame.dtype} (Inteiros de 8 bits sem sinal)\")\n",
                "\n",
                "# Boa prática: liberar o arquivo ao final\n",
                "processor.release()\n",
                "print(\"\\nRecursos liberados.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Conclusão da Parte 01\n",
                "\n",
                "Neste notebook, estabelecemos a base para o processamento de vídeo do projeto.\n",
                "\n",
                "**O que foi construído:**\n",
                "*   **Classe `VideoProcessor`:** Encapsula a complexidade do OpenCV para leitura e gerenciamento de recursos.\n",
                "*   **Padrão Generator:** Implementação de leitura frame a frame (lazy loading) para eficiência de memória.\n",
                "*   **Extração de Metadados:** Métodos para obter FPS, resolução e contagem total de frames.\n",
                "\n",
                "Com o processador de vídeo funcional, o próximo passo é implementar a detecção de faces nos frames extraídos."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (Tech Challenge Fase 04)",
            "language": "python",
            "name": "fiap-tech-challenge-fase04"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
